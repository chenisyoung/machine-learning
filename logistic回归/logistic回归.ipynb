{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# logistic 模型, 解决二分类问题\n",
    "# 由于梯度类似回归, 因此实际上只需要对h(θ)做sigmoid处理即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticRegression:\n",
    "    def __init__(self, alpha=0.001, maxIterations=5000, jd=0.001, mul=1):\n",
    "        '''\n",
    "        初始化一个GDregression\n",
    "        Params:\n",
    "            # feathreal_nums - 特征数 \n",
    "            alpha - 学习速率\n",
    "            maxIterations - 最大迭代次数\n",
    "            jd - 需求精确度\n",
    "            mul - 多项式, 待定功能\n",
    "        '''\n",
    "        # self.featureal_nums=featureal_nums\n",
    "        self.alpha = alpha\n",
    "        self.maxIterations = maxIterations\n",
    "        self.jd = jd\n",
    "        self.mul = mul\n",
    "        self._costs = []\n",
    "        \n",
    "    def _sigmoid(self, inputs):\n",
    "        # sigmoid函数 即 h(\\theta)\n",
    "        # 适用于 ndarray类型\n",
    "        # print(inputs)\n",
    "        # print('---')\n",
    "        return 1.0 / (1.0 + np.exp(-inputs))\n",
    "    #def _sigmoid(self, x):\n",
    "        #if x >= 0:\n",
    "           # return 1.0/(1 + np.exp(-x))\n",
    "       # else:\n",
    "           # return np.exp(x)/(1 + np.exp(x))\n",
    "\n",
    "    def _hypothesis(self, ts, data):\n",
    "        '''\n",
    "        使用参数列表来计算该参数对数据的预测结果\n",
    "        Params:\n",
    "            ts - 参数, 为2维数组但是每一行只能有一个值, 即类似行向量的转置, 不过ndarray 单行向量转置不会转置为二维\\\n",
    "            需要声明的时候为[[x1, x2, ...xn]]才能够进行转置\n",
    "        '''\n",
    "        # 使用添加了 值为1 的列 的数据集\n",
    "        ret = np.dot(data, ts)\n",
    "        ret = self._sigmoid(ret)\n",
    "        return ret   # 返回 一列 ndarray 数组 二维数组\n",
    "        \n",
    "    def _fill_1(self, data):\n",
    "        # 返回添加一列 1 后的特征\n",
    "        return np.concatenate([np.ones(data.shape[0]).reshape(data.shape[0], 1), data], axis=1)\n",
    "    \n",
    "    def _cost(self,ts):\n",
    "        t = self._hypothesis(ts, self._data_fill_1)\n",
    "        t = t.reshape(t.shape[0],)\n",
    "        return np.power((t - self._features), 2).sum()/2/self._data_nums\n",
    "        #return np.power((self._hypothesis(t1, t2) - self._features), 2).sum()/2/self._data_nums\n",
    "    \n",
    "    def fit(self, data, features):\n",
    "        \"\"\"\n",
    "            Params:\n",
    "                data - 训练集, 需要为二维ndarray\n",
    "                features - 标签, 需要为一维ndarray, 且为0,1值\n",
    "        \"\"\"\n",
    "        self._data = data\n",
    "        # 下面这条语句需要先判断data是二维数组才行\n",
    "        self._x, self._y = data.shape\n",
    "        self._feathres_nums = len(data[0])    # 获取特征数目    \n",
    "        self._data_nums = data.shape[0]      # 获得数据条数\n",
    "        self._data_fill_1 = self._fill_1(data)     # 补充一列1\n",
    "        self._features = features \n",
    "        self._ts = np.zeros((self._feathres_nums + 1, 1))   # 初始化参数数组全为0 得到一个二维数组表示列数组\n",
    "        self._ts += 0.5    # 二分类不能初始化为0\n",
    "        # print(self._ts)\n",
    "        self._costs.clear()\n",
    "        ts = self._ts\n",
    "        for i in range(self.maxIterations):\n",
    "        #for i in range(2): 小循环测试用\n",
    "            tp = self._hypothesis(ts, data=self._data_fill_1)    # 得到预测结果向量\n",
    "            tp = tp.reshape(tp.shape[0], )    # 将单列二维向量转变为行向量好与特征做运算\n",
    "            \n",
    "            # 以下为对应偏导公式\n",
    "            ch = tp - self._features        # 预测结果与特征的差向量\n",
    "            ch.reshape(ch.shape[0], 1)\n",
    "            dot = np.dot(self._data_fill_1.T, ch)    # 二维(data_nums, features)数据, 得到参数加1行\n",
    "            sumof = self.alpha * dot\n",
    "            sumof = sumof.reshape(self._feathres_nums+1, 1) / self._feathres_nums  # 转换为列向量 与theta做运算\n",
    "            \n",
    "            tts = ts - sumof \n",
    "            ts = tts\n",
    "            cc = self._cost(ts)\n",
    "            self._ts = ts\n",
    "            if len(self._costs) == 0:\n",
    "                pass\n",
    "            else:\n",
    "                if cc == self._costs[-1]:\n",
    "                    break\n",
    "            self._costs.append(cc)    # 存入损失值\n",
    "            if cc <= self.jd:\n",
    "                break\n",
    "        \n",
    "    \n",
    "    def predict(self, data):\n",
    "        data = self._fill_1(data)    # 填充 \"1\" 列\n",
    "        # ret = np.dot(data, self._ts)\n",
    "        # ret = np.array([sum(x) for x in ret])\n",
    "        return self._hypothesis(ts=self._ts, data=data)   # 返回 一列 ndarray 数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019年9月19日18:31:53"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer    # 引入外部数据集进行测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancers = load_breast_cancer()\n",
    "datas = cancers.data\n",
    "features = cancers.target\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()    # 特征缩放\n",
    "data2 = std.fit_transform(datas)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "data1, data2, lab1, lab2 = train_test_split(data2, features)    # 分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "logr = logisticRegression()\n",
    "logr.fit(data1, lab1)    # 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = logr.predict(data2)    # 预测\n",
    "for i in range(len(pre)):    # 需要手动对预测大于0.5的分成1\n",
    "    if pre[i] > 0.5:\n",
    "        pre[i]=1\n",
    "    else:\n",
    "        pre[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, cohen_kappa_score    # 测试方法集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "acu = accuracy_score(lab2, pre)\n",
    "prec = precision_score(lab2, pre)\n",
    "rec = recall_score(lab2, pre)\n",
    "f1 = f1_score(lab2, pre)\n",
    "cohen = cohen_kappa_score(lab2, pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "准确率为:  0.965034965034965\n",
      "精确率为:  0.9545454545454546\n",
      "召回率为:  0.9882352941176471\n",
      "f1率为:  0.9710982658959537\n",
      "cohen系数为:  0.9268841394825647\n"
     ]
    }
   ],
   "source": [
    "print('准确率为: ', acu)\n",
    "print('精确率为: ', prec)\n",
    "print('召回率为: ', rec)\n",
    "print('f1率为: ', f1)\n",
    "print('cohen系数为: ', cohen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 准确率, 精确率, 召回率, f1, cohen系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
